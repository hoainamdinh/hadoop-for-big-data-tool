# ğŸ“š HÆ°á»›ng Dáº«n CÃ i Äáº·t Big Data Stack

> **Hadoop 2.7.4 â€¢ Hive 2.3.2 â€¢ Hue 4.6.0 â€¢ Spark 3.5.1 â€¢ Python 3.10**

TÃ i liá»‡u hÆ°á»›ng dáº«n chi tiáº¿t cÃ¡ch cÃ i Ä‘áº·t vÃ  quáº£n lÃ½ mÃ´i trÆ°á»ng Big Data hoÃ n chá»‰nh sá»­ dá»¥ng Docker Compose.

---

## ğŸ“‹ Má»¥c Lá»¥c

- [ğŸ—ï¸ Kiáº¿n TrÃºc Há»‡ Thá»‘ng](#ï¸-kiáº¿n-trÃºc-há»‡-thá»‘ng)
- [âš™ï¸ YÃªu Cáº§u Há»‡ Thá»‘ng](#ï¸-yÃªu-cáº§u-há»‡-thá»‘ng)
- [ğŸš€ Khá»Ÿi Äá»™ng Nhanh](#-khá»Ÿi-Ä‘á»™ng-nhanh)
- [ğŸŒ Äá»‹a Chá»‰ Dá»‹ch Vá»¥ & Cá»•ng](#-Ä‘á»‹a-chá»‰-dá»‹ch-vá»¥--cá»•ng)
- [ğŸ› ï¸ Cáº¥u HÃ¬nh PhÃ­m Táº¯t Bash](#ï¸-cáº¥u-hÃ¬nh-phÃ­m-táº¯t-bash)
- [ğŸ“– HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng](#-hÆ°á»›ng-dáº«n-sá»­-dá»¥ng)
- [âš ï¸ LÆ°u Ã Quan Trá»ng](#ï¸-lÆ°u-Ã½-quan-trá»ng)

---

## ğŸ—ï¸ Kiáº¿n TrÃºc Há»‡ Thá»‘ng

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 bigdata-net (Docker Network)                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚               Hadoop Hive Hue                     â”‚     â”‚
â”‚  â”‚   ğŸ“¦ Hadoop NameNode (LÆ°u trá»¯ HDFS)               â”‚     â”‚
â”‚  â”‚   ğŸ“¦ Hadoop DataNode                              â”‚     â”‚
â”‚  â”‚   ğŸ“¦ YARN ResourceManager                         â”‚     â”‚
â”‚  â”‚   ğŸ“¦ Hive Metastore + PostgreSQL                  â”‚     â”‚
â”‚  â”‚   ğŸ“¦ HiveServer2 (JDBC:10000)                     â”‚     â”‚
â”‚  â”‚   ğŸ“¦ Hue Web UI (TrÃ¬nh soáº¡n SQL)                  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                          â†•                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚        Spark Cluster                              â”‚     â”‚
â”‚  â”‚   âš¡ Spark Master (Cá»•ng 7077)                     â”‚     â”‚
â”‚  â”‚   âš¡ Spark Worker (Python 3.10)                   â”‚     â”‚
â”‚  â”‚   ğŸ”— Káº¿t ná»‘i vá»›i HDFS & Hive                      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## âš™ï¸ YÃªu Cáº§u Há»‡ Thá»‘ng

| YÃªu cáº§u | Chi tiáº¿t |
|---------|----------|
| **Há»‡ Ä‘iá»u hÃ nh** | Linux (Ubuntu 20.04+) / WSL2 trÃªn Windows |
| **Docker Engine** | PhiÃªn báº£n 20.10+ |
| **Docker Compose** | PhiÃªn báº£n 1.29+ hoáº·c V2 |
| **RAM** | Tá»‘i thiá»ƒu 8GB (khuyáº¿n nghá»‹ 16GB) |
| **á»” cá»©ng** | Ãt nháº¥t 20GB trá»‘ng |

---

## ğŸš€ Khá»Ÿi Äá»™ng Nhanh

### BÆ°á»›c 1: Clone Project

Táº£i mÃ£ nguá»“n vá» mÃ¡y:

```bash
cd ~
git clone https://github.com/hoainamdinh/hadoop-for-big-data-tool.git
cd hadoop-for-big-data-tool
```

### BÆ°á»›c 2: Táº¡o Docker Network

Táº¥t cáº£ dá»‹ch vá»¥ giao tiáº¿p qua má»™t máº¡ng chung:

```bash
docker network create bigdata-net
```

### BÆ°á»›c 3: Khá»Ÿi Äá»™ng Dá»‹ch Vá»¥

**CÃ¡ch A - Khá»Ÿi Ä‘á»™ng thá»§ cÃ´ng:**
```bash
# Khá»Ÿi Ä‘á»™ng Hadoop + Hive + Hue
cd ~/hadoop-for-big-data-tool/docker-hadoop-hive-hue && docker-compose up -d

# Khá»Ÿi Ä‘á»™ng Spark
cd ~/hadoop-for-big-data-tool/docker-spark && docker-compose up -d
```

**CÃ¡ch B - DÃ¹ng phÃ­m táº¯t Bash** *(khuyáº¿n nghá»‹)*:
```bash
start-bigdata
```

### BÆ°á»›c 4: Kiá»ƒm Tra Dá»‹ch Vá»¥

Chá» 2-3 phÃºt Ä‘á»ƒ khá»Ÿi táº¡o xong, sau Ä‘Ã³ kiá»ƒm tra:

```bash
docker ps
show-links
```

---

## ğŸŒ Äá»‹a Chá»‰ Dá»‹ch Vá»¥ & Cá»•ng

| ğŸ”§ Dá»‹ch vá»¥ | ğŸŒ Äá»‹a chá»‰ | ğŸ“Œ Cá»•ng | ğŸ“ MÃ´ táº£ |
|------------|------------|---------|----------|
| **Hadoop NameNode** | http://localhost:50070 | `50070` | Giao diá»‡n HDFS - Duyá»‡t file, kiá»ƒm tra cluster |
| **Hadoop DataNode** | http://localhost:50075 | `50075` | GiÃ¡m sÃ¡t DataNode |
| **ğŸ¨ Hue Interface** | http://localhost:8888 | `8888` | **TrÃ¬nh soáº¡n SQL & Duyá»‡t file chÃ­nh** |
| **âš¡ Spark Master** | http://localhost:8080 | `8080` | Dashboard Spark cluster |
| **Spark RPC** | spark://localhost:7077 | `7077` | Äiá»ƒm submit Spark job |
| **Hive JDBC** | jdbc:hive2://localhost:10000 | `10000` | Káº¿t ná»‘i trá»±c tiáº¿p Hive |
| **Hive Metastore** | thrift://localhost:9083 | `9083` | Dá»‹ch vá»¥ metastore ná»™i bá»™ |
| **PostgreSQL** | localhost:5432 | `5432` | LÆ°u trá»¯ metadata |

### ğŸ” ThÃ´ng Tin ÄÄƒng Nháº­p Máº·c Äá»‹nh

| Dá»‹ch vá»¥ | TÃªn Ä‘Äƒng nháº­p | Máº­t kháº©u |
|---------|---------------|----------|
| **Hue** | `admin` | `admin` *(táº¡o má»›i láº§n Ä‘áº§u Ä‘Äƒng nháº­p)* |
| **PostgreSQL** | `hive` | `hive` |

---

## ğŸ› ï¸ Cáº¥u HÃ¬nh PhÃ­m Táº¯t Bash

ThÃªm cÃ¡c hÃ m sau vÃ o file `~/.bashrc` Ä‘á»ƒ quáº£n lÃ½ tiá»‡n lá»£i:

```bash
# ==========================================
# ğŸ¯ PHÃM Táº®T BIG DATA STACK
# ==========================================

# ğŸš€ Khá»Ÿi Ä‘á»™ng toÃ n bá»™ Big Data stack
start-bigdata() {
    echo "ğŸŒ Äang táº¡o network..."
    docker network create bigdata-net 2>/dev/null || echo "âœ… Network Ä‘Ã£ tá»“n táº¡i"
    
    echo "ğŸ˜ Äang khá»Ÿi Ä‘á»™ng Hadoop + Hive + Hue..."
    (cd "~/hadoop-for-big-data-tool/docker-hadoop-hue-hive" && docker-compose up -d)
    
    echo "âš¡ Äang khá»Ÿi Ä‘á»™ng Spark cluster..."
    (cd "~/hadoop-for-big-data-tool/docker-spark" && docker-compose up -d)
    
    echo "âœ… ÄÃ£ khá»Ÿi Ä‘á»™ng xong! Chá» 2-3 phÃºt Ä‘á»ƒ cÃ¡c dá»‹ch vá»¥ sáºµn sÃ ng."
    show-links
}

# ğŸ›‘ Táº¯t toÃ n bá»™ Big Data stack
stop-bigdata() {
    echo "âš¡ Äang táº¯t Spark..."
    (cd "~/hadoop-for-big-data-tool/docker-spark" && docker-compose down)
    
    echo "ğŸ˜ Äang táº¯t Hadoop + Hive + Hue..."
    (cd "~/hadoop-for-big-data-tool/docker-hadoop-hue-hive" && docker-compose down)
    
    echo "âœ… ÄÃ£ táº¯t toÃ n bá»™ dá»‹ch vá»¥."
}

# ğŸ“Š Hiá»ƒn thá»‹ báº£ng thÃ´ng tin dá»‹ch vá»¥
show-links() {
    echo ""
    echo "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—"
    echo "â•‘           ğŸ¯ Báº¢NG ÄIá»€U KHIá»‚N BIG DATA                     â•‘"
    echo "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"
    printf "â•‘ %-20s â”‚ %-35s â•‘\n" "ğŸ”§ Dá»ŠCH Vá»¤" "ğŸŒ Äá»ŠA CHá»ˆ"
    echo "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£"
    printf "â•‘ %-20s â”‚ %-35s â•‘\n" "Hadoop NameNode" "http://localhost:50070"
    printf "â•‘ %-20s â”‚ %-35s â•‘\n" "Hadoop DataNode" "http://localhost:50075"
    printf "â•‘ %-20s â”‚ %-35s â•‘\n" "ğŸ¨ Hue Interface" "http://localhost:8888"
    printf "â•‘ %-20s â”‚ %-35s â•‘\n" "âš¡ Spark Master" "http://localhost:8080"
    printf "â•‘ %-20s â”‚ %-35s â•‘\n" "Spark RPC" "spark://localhost:7077"
    printf "â•‘ %-20s â”‚ %-35s â•‘\n" "Hive JDBC" "jdbc:hive2://localhost:10000"
    echo "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo "  ğŸ’¡ ÄÄƒng nháº­p Hue: admin/admin (hoáº·c táº¡o má»›i láº§n Ä‘áº§u)"
    echo "  ğŸ”„ Xem láº¡i báº£ng nÃ y: show-links"
    echo ""
}

# ğŸ” Kiá»ƒm tra nhanh tráº¡ng thÃ¡i
bigdata-status() {
    echo "ğŸ“Š Tráº¡ng thÃ¡i Container:"
    docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}" | grep -E "namenode|hive|hue|spark|datanode|resourcemanager"
}
```

Sau khi lÆ°u file, Ã¡p dá»¥ng thay Ä‘á»•i:

```bash
source ~/.bashrc
```

---

## ğŸ“– HÆ°á»›ng Dáº«n Sá»­ Dá»¥ng

### CÃ¡c Lá»‡nh HÃ ng NgÃ y

| Lá»‡nh | MÃ´ táº£ |
|------|-------|
| `start-bigdata` | ğŸš€ Khá»Ÿi Ä‘á»™ng táº¥t cáº£ dá»‹ch vá»¥ |
| `stop-bigdata` | ğŸ›‘ Táº¯t táº¥t cáº£ dá»‹ch vá»¥ |
| `show-links` | ğŸ“Š Hiá»ƒn thá»‹ Ä‘á»‹a chá»‰ dá»‹ch vá»¥ |
| `bigdata-status` | ğŸ” Kiá»ƒm tra tráº¡ng thÃ¡i container |

### MÃ´ Táº£ Dá»‹ch Vá»¥

| Dá»‹ch vá»¥ | Chá»©c nÄƒng |
|---------|-----------|
| **ğŸ˜ Hadoop NameNode** | Quáº£n lÃ½ HDFS - xem dung lÆ°á»£ng, duyá»‡t file |
| **ğŸ¨ Hue (8888)** | **NÆ¡i lÃ m viá»‡c chÃ­nh** - soáº¡n SQL, duyá»‡t file, quáº£n lÃ½ job |
| **âš¡ Spark Master** | GiÃ¡m sÃ¡t Spark cluster, worker vÃ  á»©ng dá»¥ng Ä‘ang cháº¡y |
| **ğŸ HiveServer2** | Thá»±c thi truy váº¥n Hive qua káº¿t ná»‘i JDBC |

---

## âš ï¸ LÆ°u Ã Quan Trá»ng

### ğŸ• Thá»i Gian Khá»Ÿi Äá»™ng
> Má»™t sá»‘ dá»‹ch vá»¥ (Hive Metastore, Hue) cáº§n **1-2 phÃºt** sau khi container hiá»‡n "Up" Ä‘á»ƒ hoáº¡t Ä‘á»™ng Ä‘áº§y Ä‘á»§. Náº¿u gáº·p lá»—i, hÃ£y chá» vÃ  thá»­ láº¡i.

### ğŸ“ File Cáº¥u HÃ¬nh

| File | Vá»‹ trÃ­ | Má»¥c Ä‘Ã­ch |
|------|--------|----------|
| `hue-overrides.ini` | `docker-hadoop-hue-hive/` | Ghi Ä‘Ã¨ cáº¥u hÃ¬nh Hue |
| `hadoop-hive.env` | `docker-hadoop-hue-hive/` | Biáº¿n mÃ´i trÆ°á»ng |
| `spark-defaults.conf` | `docker-spark/` | Cáº¥u hÃ¬nh Spark |
| `hive-site.xml` | `docker-spark/` | Káº¿t ná»‘i Hive cho Spark |

### ğŸ’¾ LÆ°u Trá»¯ Dá»¯ Liá»‡u
- Metadata cá»§a Hive Ä‘Æ°á»£c lÆ°u trong PostgreSQL
- Dá»¯ liá»‡u HDFS Ä‘Æ°á»£c lÆ°u trong Docker volumes
- **Cáº£nh bÃ¡o**: Cháº¡y `docker-compose down -v` sáº½ xÃ³a toÃ n bá»™ dá»¯ liá»‡u!

### ğŸ”§ Xá»­ LÃ½ Sá»± Cá»‘

| Váº¥n Ä‘á» | Giáº£i phÃ¡p |
|--------|-----------|
| KhÃ´ng tÃ¬m tháº¥y network | Cháº¡y `docker network create bigdata-net` |
| Dá»‹ch vá»¥ khÃ´ng pháº£n há»“i | Chá» 2-3 phÃºt, kiá»ƒm tra `docker logs <container>` |
| Cá»•ng Ä‘Ã£ Ä‘Æ°á»£c sá»­ dá»¥ng | Kiá»ƒm tra `netstat -tlnp \| grep <port>` vÃ  táº¯t dá»‹ch vá»¥ xung Ä‘á»™t |
| Hue bá»‹ khÃ³a database | Restart container: `docker restart <hue-container>` |

---

## ğŸ“ Cáº¥u TrÃºc Dá»± Ãn

```
â”œâ”€â”€ ğŸ“‚ docker-hadoop-hue-hive/          # Stack Hadoop + Hive + Hue
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ hadoop-hive.env
â”‚   â””â”€â”€ hue-overrides.ini
â”‚
â”œâ”€â”€ ğŸ“‚ docker-spark/            # Spark cluster
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â”œâ”€â”€ spark-defaults.conf
â”‚   â””â”€â”€ hive-site.xml
â”‚
â””â”€â”€ ğŸ“„ guide.md                 # TÃ i liá»‡u nÃ y
```

---

## ğŸ“œ Giáº¥y PhÃ©p

Dá»± Ã¡n nÃ y phá»¥c vá»¥ má»¥c Ä‘Ã­ch há»c táº­p.

---

**ÄÆ°á»£c táº¡o vá»›i â¤ï¸ cho viá»‡c há»c Big Data**
